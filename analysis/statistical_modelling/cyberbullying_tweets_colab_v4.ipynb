{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 778
        },
        "id": "QtqlP0I4oYR8",
        "outputId": "a3e38152-d092-4d82-bb31-eda50f93a482"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label\n",
            "1    7998\n",
            "0    7992\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-3-eef013bfc1c7>:84: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjkos0012\u001b[0m (\u001b[33mjkos0012-monash-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250428_090959-336mhe27</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/jkos0012-monash-university/huggingface/runs/336mhe27' target=\"_blank\">./cyberbully_results</a></strong> to <a href='https://wandb.ai/jkos0012-monash-university/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/jkos0012-monash-university/huggingface' target=\"_blank\">https://wandb.ai/jkos0012-monash-university/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/jkos0012-monash-university/huggingface/runs/336mhe27' target=\"_blank\">https://wandb.ai/jkos0012-monash-university/huggingface/runs/336mhe27</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3200' max='3200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3200/3200 19:30, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.076600</td>\n",
              "      <td>0.008448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>0.015388</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.012758</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [100/100 00:14]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation metrics: {'eval_loss': 0.008448093198239803, 'eval_runtime': 14.1312, 'eval_samples_per_second': 226.307, 'eval_steps_per_second': 7.077, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/pipelines/text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample : Go back to the nursery, kid!\n",
            "Scores : [[{'label': 'age', 'score': 0.9958167672157288}, {'label': 'religion', 'score': 0.0041832467541098595}]]\n"
          ]
        }
      ],
      "source": [
        "# ────────────────────────────── installs ──────────────────────────────\n",
        "# !pip install -qU pandas scikit-learn torch transformers datasets\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from transformers import (\n",
        "    BertTokenizer, BertForSequenceClassification,\n",
        "    TrainingArguments, Trainer, pipeline\n",
        ")\n",
        "\n",
        "# ═══════════════════ 1. Load & filter dataset ═════════════════════════\n",
        "df = pd.read_csv(\"cyberbullying_tweets_cleaned.csv\")\n",
        "\n",
        "wanted = [\"age\", \"religion\"]\n",
        "df = df[df[\"cyberbullying_type\"].isin(wanted)].copy()\n",
        "\n",
        "label_map  = {\"age\": 0, \"religion\": 1}\n",
        "df[\"label\"] = df[\"cyberbullying_type\"].map(label_map)\n",
        "\n",
        "print(df[\"label\"].value_counts())   # check class balance\n",
        "\n",
        "# ═══════════════════ 2. Train / val split ════════════════════════════\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    df[\"cleaned_text\"].astype(str).tolist(),\n",
        "    df[\"label\"].tolist(),\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=df[\"label\"]\n",
        ")\n",
        "\n",
        "# ═══════════════════ 3. Tokenise ═════════════════════════════════════\n",
        "tok = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "train_enc = tok(train_texts, truncation=True, padding=True, max_length=128)\n",
        "val_enc   = tok(val_texts,   truncation=True, padding=True, max_length=128)\n",
        "\n",
        "class CyberDS(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            \"input_ids\": torch.tensor(self.encodings[\"input_ids\"][idx]),\n",
        "            \"attention_mask\": torch.tensor(self.encodings[\"attention_mask\"][idx]),\n",
        "            \"labels\": torch.tensor(self.labels[idx])\n",
        "        }\n",
        "\n",
        "\n",
        "train_ds = CyberDS(train_enc, train_labels)\n",
        "val_ds   = CyberDS(val_enc,   val_labels)\n",
        "\n",
        "# ═══════════════════ 4. Model with correct label names ═══════════════\n",
        "id2label = {0: \"age\", 1: \"religion\"}\n",
        "label2id = {v: k for k, v in id2label.items()}\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    num_labels=2,\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        "    problem_type=\"single_label_classification\"\n",
        ")\n",
        "\n",
        "# ═══════════════════ 5. Training setup ═══════════════════════════════\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"./cyberbully_results\",\n",
        "    num_train_epochs=4,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=32,\n",
        "    eval_strategy=\"epoch\",\n",
        "    warmup_steps=100,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=10,\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_ds,\n",
        "    eval_dataset=val_ds,\n",
        "    tokenizer=tok,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "metrics = trainer.evaluate()\n",
        "print(\"Validation metrics:\", metrics)\n",
        "\n",
        "# After trainer.train()\n",
        "torch.save(model.state_dict(), \"bert_cyberbullying.pth\")\n",
        "\n",
        "\n",
        "# ═══════════════════ 6. Save fine-tuned model ════════════════════════\n",
        "SAVE_DIR = \"bert-cyberbullying\"\n",
        "model.save_pretrained(SAVE_DIR)\n",
        "tok.save_pretrained(SAVE_DIR)\n",
        "\n",
        "# ═══════════════════ 7. Quick inference demo ════════════════════════\n",
        "clf = pipeline(\n",
        "    \"text-classification\",\n",
        "    model=SAVE_DIR,\n",
        "    tokenizer=SAVE_DIR,\n",
        "    return_all_scores=True\n",
        ")\n",
        "\n",
        "sample = \"Go back to the nursery, kid!\"\n",
        "print(\"\\nSample :\", sample)\n",
        "print(\"Scores :\", clf(sample))\n",
        "#Replace this code from your current model code"
      ]
    }
  ]
}